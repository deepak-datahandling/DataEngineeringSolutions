{"cells":[{"cell_type":"markdown","source":["### Weather Details(JSON) Batch processing using **Py-Spark**"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"67a0a301-6ee5-49b2-9be4-64bdd5a3f072"},{"cell_type":"code","source":["from pyspark.sql.functions import *\n","from pyspark.sql import *\n","\n","src_df=spark.read.\\\n","option('multiline','true').\\\n","format('json').\\\n","load(\"Files/WeatherDetails_Stream/*.json\")\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3c279c0d-2ada-4939-8e1d-b7e6022f08c7"},{"cell_type":"code","source":["#read Country Details Table\n","country_df = spark.sql(\"SELECT * FROM LHDEV.countrydetails\")\n","Joined_df=src_df.join(country_df,col('location.country')==col('Country'),'inner')\\\n","                .filter(col('location.region')!='Anhui')\\\n","                .filter(col('location.region')!='Ghazni')\\\n","                .withColumn('WeatherID',col('current.weather_code').cast('int'))\\\n","                .withColumn('AtmosphereID',concat(col('CountryCode'),substring(col('location.country'),-3,3)))\n","                \n","\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"8286bf8e-3c8b-4f87-8b50-ed3485f87977"},{"cell_type":"code","source":["#ID Details -- FactTable\n","#SCD Type - 1\n","fact_df=Joined_df.withColumn('Load_TS',current_timestamp()).select(['CountryCode','WeatherID','AtmosphereID','Load_TS'])"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ff65f956-f865-4a21-a815-70cc993b49bf"},{"cell_type":"code","source":["#countryDetails --DimentionTable\n","#SCD Type - 1\n","country_df_final=Joined_df.withColumn('City',split(col('request.query'),',').getItem(0)).\\\n","                            withColumn('Latitude',col('location.lat').cast('decimal(8,6)')).\\\n","                            withColumn('Longitude',col('location.lon').cast('decimal(9,6)')).\\\n","                            select(['CountryCode','City','Country','Region','Latitude','Longitude']).distinct().dropDuplicates(['CountryCode'])"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"53343668-a7d0-40a0-8a4d-78f1dde1f98a"},{"cell_type":"code","source":["#AtmosphereDetails --DimentionTable\n","#SCD Type - 2\n","atmosphere_df=Joined_df.withColumn('CloundCover',concat(col('current.cloudcover').cast('int'),lit('%')))\\\n","                        .withColumn('Humidity',concat(col('current.humidity').cast('int'),lit('%')))\\\n","                        .withColumn('is_day',col('current.is_day'))\\\n","                        .withColumn('temperature',concat(col('current.temperature').cast('int'),lit('Â°C')))\\\n","                        .withColumn('wind_degree',concat(col('current.wind_degree').cast('int'),lit('%')))\\\n","                        .withColumn('wind_direction',col('current.wind_dir'))\\\n","                        .withColumn('wind_speed',concat(col('current.wind_speed').cast('int'),lit(' Km/hr')))\\\n","                        .withColumn('observation_time',to_timestamp((concat(substring(col('location.localtime'),1,10),col('current.observation_time'))),'yyyy-MM-ddhh:mm a'))\\\n","                        .withColumn('is_latest',lit(1))\\\n","                        .select(['AtmosphereID','observation_time','temperature','Humidity','CloundCover','wind_direction','wind_degree','wind_speed','is_day','is_latest','WeatherID'])\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4c9dd9ac-260d-4f17-af65-cbfe7bb36517"},{"cell_type":"code","source":["#WeatherDetails --DimentionTable\n","#SCD Type - 1\n","weather_df=Joined_df.withColumn('weather_descriptions',col('current.weather_descriptions')[0])\\\n","                    .select(['WeatherID','weather_descriptions']).distinct().dropDuplicates(['WeatherID'])\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"f5bfd316-af57-4018-b432-225ac077a888"},{"cell_type":"code","source":["#Creating Dict of ID and TableNames for future uses\n","tble_dict={'CountryCode':'CountryDetFinal','WeatherID':'WeatherDet','AtmosphereID':'AtmosphereDet'}"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e12ce822-b4dd-4961-8ce9-f90f51f3e165"},{"cell_type":"code","source":["def process_batch(df):\n","    '''\n","    A function which takes inputs as dataframe(df) and perform the MERGE opertion\n","    Based on the certain conditions.\n","    '''\n","    id_col=[x for x in df.columns if x in ['CountryCode','WeatherID','AtmosphereID']]\n","    if len(id_col) == 3:\n","        df.createOrReplaceTempView(\"incoming_df\")\n","        spark.sql(f'''MERGE INTO countrymstr T USING incoming_df A on T.CountryCode=A.CountryCode\n","                    WHEN MATCHED THEN UPDATE SET\n","                    T.WeatherID=A.WeatherID,\n","                    T.AtmosphereID=A.AtmosphereID,\n","                    T.Load_TS=CURRENT_TIMESTAMP\n","                    WHEN NOT MATCHED THEN\n","                    INSERT\n","                    * ''')\n","    elif len(id_col) == 2:\n","        df.createOrReplaceTempView(\"incoming_df\")\n","        spark.sql(f'''MERGE INTO atmospheredet T USING incoming_df A on T.is_latest=A.is_latest\n","                    AND T.AtmosphereID=A.AtmosphereID\n","                    AND T.observation_time <= A.observation_time\n","                    WHEN MATCHED THEN UPDATE SET T.is_latest=0\n","                    ''')\n","        spark.sql(f'''MERGE INTO atmospheredet T USING incoming_df A on T.is_latest=A.is_latest\n","                    AND T.AtmosphereID=A.AtmosphereID\n","                    AND T.observation_time <= A.observation_time\n","                    WHEN NOT MATCHED THEN\n","                    INSERT\n","                    * ''')\n","    else:    \n","        tble=tble_dict[id_col[0]]\n","        df.createOrReplaceTempView(\"incoming_df\")\n","        spark.sql(f'''MERGE INTO {tble} T USING incoming_df A on T.{id_col[0]}=A.{id_col[0]}\n","                    WHEN NOT MATCHED THEN\n","                    INSERT\n","                    * ''')\n","\n","    "],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"cee26db7-5156-4c98-84ba-21b76278327f"},{"cell_type":"code","source":["#Loading CountryMaster Table\n","process_batch(fact_df)\n","\n","#Loading Atmosphere Details Table\n","process_batch(atmosphere_df)\n","\n","#Loading Country Details Final Table\n","process_batch(country_df_final)\n","\n","#Loading Weather Details Table\n","process_batch(weather_df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"c61da3c9-3a9c-4a07-a4d8-dbd684826b7d"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"780e9978-6322-4fcd-a5cc-be63a6622edc","default_lakehouse_name":"LHDEV","default_lakehouse_workspace_id":"7b0d371b-149a-4df5-b9ef-5f580e3f2f0a"}}},"nbformat":4,"nbformat_minor":5}